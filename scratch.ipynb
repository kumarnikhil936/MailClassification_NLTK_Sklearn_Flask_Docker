{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adb1e96",
   "metadata": {},
   "source": [
    "- For dealing with text related tasks, we will be using nltk. \n",
    "- For machine learning related tasks, we will be using scikit-learn library.\n",
    "\n",
    "![title](misc/workflow.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a14793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nikhilkumarjha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nikhilkumarjha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nikhilkumarjha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nikhilkumarjha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from loguru import logger\n",
    "from shutil import copy\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "from joblib import dump, load\n",
    "from operator import itemgetter\n",
    "\n",
    "import re\n",
    "import yaml\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from src.helpers import preprocess_single_text, load_mapping\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 300\n",
    "pd.options.display.max_colwidth = 100\n",
    "np.set_printoptions(threshold=2000)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logger.add(\"logs/{time}.log\")\n",
    "logger.add(sys.stdout, colorize=True, format=\"<green>{time}</green> <level>{message}</level>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305fb175",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab52241a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.026 | INFO     | __main__:load_data:10 - File: dataset/dataset_1.json - 303 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.026581+0100\u001b[0m \u001b[1mFile: dataset/dataset_1.json - 303 rows\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.039 | INFO     | __main__:load_data:10 - File: dataset/dataset_5.json - 237 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.039232+0100\u001b[0m \u001b[1mFile: dataset/dataset_5.json - 237 rows\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.060 | INFO     | __main__:load_data:10 - File: dataset/dataset_4.json - 333 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.060940+0100\u001b[0m \u001b[1mFile: dataset/dataset_4.json - 333 rows\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.072 | INFO     | __main__:load_data:10 - File: dataset/dataset_3.json - 37 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.072553+0100\u001b[0m \u001b[1mFile: dataset/dataset_3.json - 37 rows\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.082 | INFO     | __main__:load_data:10 - File: dataset/dataset_2.json - 985 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.082450+0100\u001b[0m \u001b[1mFile: dataset/dataset_2.json - 985 rows\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def load_data(data_folder=\"dataset/\"):\n",
    "    filepaths = [join(data_folder, f) for f in listdir(data_folder) if (isfile(join(data_folder, f))) and (\"json\" in f)]\n",
    "\n",
    "    data = []\n",
    "    target = []\n",
    "\n",
    "    for ind, f in enumerate(filepaths):\n",
    "        class_name = f.split(\".\")[0].split(\"_\")[-1]\n",
    "        json_data = pd.read_json(f).values.tolist()\n",
    "        logger.info(f'File: {f} - {len(json_data)} rows')\n",
    "        data.extend([item for sublist in json_data for item in sublist])\n",
    "        target.extend([class_name] * len(json_data))\n",
    "        \n",
    "    return data, target\n",
    "\n",
    "data, target = load_data(data_folder=\"dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e6c7ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.129 | INFO     | __main__:load_data:10 - File: dataset/old/dataset_1.json - 353 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.129968+0100\u001b[0m \u001b[1mFile: dataset/old/dataset_1.json - 353 rows\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.153 | INFO     | __main__:load_data:10 - File: dataset/old/dataset_5.json - 139 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.153557+0100\u001b[0m \u001b[1mFile: dataset/old/dataset_5.json - 139 rows\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.163 | INFO     | __main__:load_data:10 - File: dataset/old/dataset_4.json - 392 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.163713+0100\u001b[0m \u001b[1mFile: dataset/old/dataset_4.json - 392 rows\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.181 | INFO     | __main__:load_data:10 - File: dataset/old/dataset_3.json - 28 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.181741+0100\u001b[0m \u001b[1mFile: dataset/old/dataset_3.json - 28 rows\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:11:26.190 | INFO     | __main__:load_data:10 - File: dataset/old/dataset_2.json - 210 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:11:26.190097+0100\u001b[0m \u001b[1mFile: dataset/old/dataset_2.json - 210 rows\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "old_data, old_target = load_data(data_folder=\"dataset/old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dab01f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def load_mapping(mapping_file='dataset/mapping.yaml'):\n",
    "    with open(mapping_file, 'r') as f:\n",
    "        mapping = yaml.safe_load(f)\n",
    "\n",
    "    mapping_dict = {}\n",
    "    _ = [mapping_dict.update({f\"{el[0]}\":f\"{el[1]}\"}) for el in \n",
    "         [(el.split('=')[0].split('.')[0].split('_')[1], el.split('=')[1].strip()) for el in mapping]]\n",
    "    \n",
    "    return mapping_dict\n",
    "\n",
    "mapping_dict = load_mapping(mapping_file='dataset/mapping.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df0f79f",
   "metadata": {},
   "source": [
    "### Preprocess data\n",
    "- Remove unwanted chars and symbols\n",
    "- Tokenize\n",
    "- Stemming / Lemmatize\n",
    "- Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a253773",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def stopword_removal(text, stop_words, curated_stop_words=None):\n",
    "    if curated_stop_words is not None and isinstance(curated_stop_words, list):\n",
    "        stop_words.update(curated_stop_words)\n",
    "\n",
    "    text = text.lower()\n",
    "    token = word_tokenize(text)\n",
    "    \n",
    "    return ' '.join([w for w in token if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "478de127",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def text_cleaner(text):\n",
    "    rules = [\n",
    "        {r'\\n': u' '}, # remove new line character\n",
    "        {r'\\t': u' '}, # remove tab character\n",
    "        {r'ß': u'ss'}, # replace ä with ae\n",
    "        {r'ä': u'ae'}, # replace ä with ae\n",
    "        {r'ü': u'ue'}, # replace ü with ue\n",
    "        {r'ö': u'oe'}, # replace ö with oe\n",
    "        {r'oe': u'o'}, # replace oe with o\n",
    "        {r'ue': u'u'}, # replace ue with u\n",
    "        {r'ae': u'a'}, # replace ae with a\n",
    "        {r'xxx': u' '}, # remove xxx word\n",
    "        {r'[^A-Za-zÀ-ž ]': u' '},  # keep only ASCII + European Chars and whitespace, no digits\n",
    "        {r'>\\s+': u'>'},  # remove spaces after a tag opens or closes\n",
    "        {r'\\s+': u' '},  # replace consecutive spaces\n",
    "        {r'\\s*<br\\s*/?>\\s*': u'\\n'},  # newline after a <br>\n",
    "        {r'</(div)\\s*>\\s*': u'\\n'},  # newline after </p> and </div> and <h1/>...\n",
    "        {r'</(p|h\\d)\\s*>\\s*': u'\\n\\n'},  # newline after </p> and </div> and <h1/>...\n",
    "        {r'<head>.*<\\s*(/head|body)[^>]*>': u''},  # remove <head> to </head>\n",
    "        {r'<a\\s+href=\"([^\"]+)\"[^>]*>.*</a>': r'\\1'},  # show links instead of texts\n",
    "        {r'[ \\t]*<[^<]*?/?>': u''},  # remove remaining tags\n",
    "        {r'^\\s+': u''},  # remove spaces at the beginning\n",
    "        {r'\\b[A-Za-zÀ-ž]\\b': u''} # remove single character words\n",
    "    ]\n",
    "    \n",
    "    for rule in rules:\n",
    "        for (k, v) in rule.items():\n",
    "            regex = re.compile(k)\n",
    "            text = regex.sub(v, text)\n",
    "        text = text.rstrip()\n",
    "        \n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "914f263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def do_stemming(text, stemmer):\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    \n",
    "    return ''.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e2e5d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def preprocess_text(text, stop_words=None, curated_stop_words=None, stemming=False, stemmer=None):\n",
    "    text = text_cleaner(text)\n",
    "    \n",
    "    if stop_words is not None:\n",
    "        text = stopword_removal(text, stop_words, curated_stop_words)\n",
    "    \n",
    "    if stemming:\n",
    "        text = do_stemming(text, stemmer)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13082eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiermit mochte abtrittserklarung versicherung nr daur mitteilen rechnungen tierarzt dr bertelsmann kleintierpraxis mohnestr arnsberg kommen sollen zukunft arzt abgerechnet kontodaten tierarzt\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('german')\n",
    "\n",
    "stop_words = set(stopwords.words('german'))\n",
    "with open('dataset/stopwords.yaml', 'r') as f:\n",
    "    curated_stop_words = yaml.safe_load(f)\n",
    "    \n",
    "processed_data = [preprocess_text(text, \n",
    "                                  stop_words=stop_words, \n",
    "                                  curated_stop_words=curated_stop_words, \n",
    "                                  stemming=True, \n",
    "                                  stemmer=stemmer) for text in data]\n",
    "\n",
    "text = \"Hiermit möchte ich meine Abtrittserklärung für meine Versicherung Nr.178718252 auf dauer mitteilen.Rechnungen die von meinem Tierarzt Dr.H.D.Bertelsmann , kleintierpraxis Möhnestr.106, 59755Arnsberg kommen sollen alle in Zukunft mit dem Arzt abgerechnet werden.Hier die  Kontodaten vom Tierarzt.\"\n",
    "print(preprocess_text(text, stop_words=stop_words, curated_stop_words=curated_stop_words, stemming=True, stemmer=stemmer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144d800d",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b07ddb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>bezugnehmend auf ihre eMail vom xxx d.M. übersende ich Ihnen\\ndie Tierarztrechnung(siehe Anhang).</td>\n",
       "      <td>bezugnehmend email ubersende tierarztrechnung siehe anhang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>unser gemeinsamer Kunde Frau xxx hat eine Rechnung zur Kostenerstattung für seine Hundekrankenve...</td>\n",
       "      <td>gemeinsamer kunde rechnung kostenerstattung hundekrankenversicherung eingereicht bearbeiten anfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>eine weitere Rechnung zu o.g. Versicherung mit der Bitte um Bearbeitung.</td>\n",
       "      <td>weitere rechnung versicherung bearbeitung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>Bitte um Rückerstattung folgender Rechnung für Hund xxx Versicherung xxx</td>\n",
       "      <td>ruckerstattung folgender rechnung hund versicherung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>anbei reiche ich Ihnen die Rechnung der Kundin mit der Ritte um Erstattung ein.\\nDas Fäden ziehe...</td>\n",
       "      <td>anbei reiche rechnung kundin ritte erstattung faden ziehen rechnung durchgefuhrten sterilisation...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   before  \\\n",
       "1176    bezugnehmend auf ihre eMail vom xxx d.M. übersende ich Ihnen\\ndie Tierarztrechnung(siehe Anhang).   \n",
       "1615  unser gemeinsamer Kunde Frau xxx hat eine Rechnung zur Kostenerstattung für seine Hundekrankenve...   \n",
       "292                              eine weitere Rechnung zu o.g. Versicherung mit der Bitte um Bearbeitung.   \n",
       "1486                             Bitte um Rückerstattung folgender Rechnung für Hund xxx Versicherung xxx   \n",
       "1328  anbei reiche ich Ihnen die Rechnung der Kundin mit der Ritte um Erstattung ein.\\nDas Fäden ziehe...   \n",
       "\n",
       "                                                                                                    after  \n",
       "1176                                           bezugnehmend email ubersende tierarztrechnung siehe anhang  \n",
       "1615  gemeinsamer kunde rechnung kostenerstattung hundekrankenversicherung eingereicht bearbeiten anfr...  \n",
       "292                                                             weitere rechnung versicherung bearbeitung  \n",
       "1486                                                  ruckerstattung folgender rechnung hund versicherung  \n",
       "1328  anbei reiche rechnung kundin ritte erstattung faden ziehen rechnung durchgefuhrten sterilisation...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "before_after_preprocessing = pd.DataFrame([data, processed_data]).T\n",
    "before_after_preprocessing.columns = ['before', 'after']\n",
    "before_after_preprocessing.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ea722d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rechnung            1116\n",
       "anbei                736\n",
       "kostenerstattung     705\n",
       "erstattung           424\n",
       "kunden               392\n",
       "konto                359\n",
       "kontaktieren         338\n",
       "bearbeiten           338\n",
       "eingereicht          337\n",
       "kunde                332\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = pd.Series(\" \".join(before_after_preprocessing[\"after\"]).split()).value_counts()\n",
    "word_count[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e0be54",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e2445dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@logger.catch\n",
    "def random_train_test_split(processed_data, target):\n",
    "    test_inds = random.sample(range(len(data)), len(data)//5)\n",
    "    train_inds = list(set(range(len(data))) - set(test_inds))\n",
    "\n",
    "    train_x = list(itemgetter(*train_inds)(processed_data))\n",
    "    test_x = list(itemgetter(*test_inds)(processed_data))\n",
    "    train_y = list(itemgetter(*train_inds)(target))\n",
    "    test_y = list(itemgetter(*test_inds)(target))\n",
    "    \n",
    "    return train_x, test_x, train_y, test_y\n",
    "\n",
    "train_x, test_x, train_y, test_y = random_train_test_split(processed_data, target)\n",
    "metrics_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4281abe0",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a9612cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:17.210 | INFO     | __main__:<module>:6 - Each word is represented by a vector of length 2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:17.210273+0100\u001b[0m \u001b[1mEach word is represented by a vector of length 2000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:17.213 | INFO     | __main__:<module>:9 - Original sentence:\n",
      "tierverischerung vertragsnummer\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:17.213575+0100\u001b[0m \u001b[1mOriginal sentence:\n",
      "tierverischerung vertragsnummer\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:17.229 | INFO     | __main__:<module>:15 - Vector representation of sentence:\n",
      "    tierverischerung  vertragsnummer\n",
      "0          0.892814        0.450426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:17.229374+0100\u001b[0m \u001b[1mVector representation of sentence:\n",
      "    tierverischerung  vertragsnummer\n",
      "0          0.892814        0.450426\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, max_features=2000)\n",
    "vectorizer.fit(processed_data)\n",
    "\n",
    "train_x_vec = vectorizer.transform(train_x)\n",
    "test_x_vec = vectorizer.transform(test_x)\n",
    "logger.info(f'Each word is represented by a vector of length {train_x_vec.shape[1]}')\n",
    "\n",
    "# Compare original text with its numeric vector representation\n",
    "logger.info(f\"Original sentence:\\n{train_x[0]}\\n\")\n",
    "\n",
    "# Feature Matrix\n",
    "features = pd.DataFrame(train_x_vec[0].toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "nonempty_features = features.loc[:, (features != 0).any(axis=0)]\n",
    "logger.info(f\"Vector representation of sentence:\\n {nonempty_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "00e90e43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:17.765 | INFO     | __main__:<module>:13 - Classifiers to test: ['LogisticRegression', 'RandomForestClassifier', 'GradientBoostingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'SGDClassifier']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:17.765994+0100\u001b[0m \u001b[1mClassifiers to test: ['LogisticRegression', 'RandomForestClassifier', 'GradientBoostingClassifier', 'DecisionTreeClassifier', 'KNeighborsClassifier', 'SGDClassifier']\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:17.770 | INFO     | __main__:<module>:18 - Training classifier: LogisticRegression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:17.770416+0100\u001b[0m \u001b[1mTraining classifier: LogisticRegression\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:18.120 | INFO     | __main__:<module>:24 - Results for LogisticRegression:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:18.120694+0100\u001b[0m \u001b[1mResults for LogisticRegression:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:18.122 | INFO     | __main__:<module>:25 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.30      0.31        40\n",
      "           2       0.79      0.89      0.84       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.85      0.72      0.78        71\n",
      "           5       1.00      0.87      0.93        52\n",
      "\n",
      "    accuracy                           0.78       379\n",
      "   macro avg       0.59      0.55      0.57       379\n",
      "weighted avg       0.77      0.78      0.77       379\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:18.122584+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.32      0.30      0.31        40\n",
      "           2       0.79      0.89      0.84       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.85      0.72      0.78        71\n",
      "           5       1.00      0.87      0.93        52\n",
      "\n",
      "    accuracy                           0.78       379\n",
      "   macro avg       0.59      0.55      0.57       379\n",
      "weighted avg       0.77      0.78      0.77       379\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:18.124 | INFO     | __main__:<module>:18 - Training classifier: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:18.124649+0100\u001b[0m \u001b[1mTraining classifier: RandomForestClassifier\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:21.412 | INFO     | __main__:<module>:24 - Results for RandomForestClassifier:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:21.412204+0100\u001b[0m \u001b[1mResults for RandomForestClassifier:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:21.414 | INFO     | __main__:<module>:25 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.38      0.37        40\n",
      "           2       0.80      0.87      0.83       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.86      0.72      0.78        71\n",
      "           5       0.98      0.88      0.93        52\n",
      "\n",
      "    accuracy                           0.78       379\n",
      "   macro avg       0.60      0.57      0.58       379\n",
      "weighted avg       0.78      0.78      0.78       379\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:21.414136+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.38      0.37        40\n",
      "           2       0.80      0.87      0.83       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.86      0.72      0.78        71\n",
      "           5       0.98      0.88      0.93        52\n",
      "\n",
      "    accuracy                           0.78       379\n",
      "   macro avg       0.60      0.57      0.58       379\n",
      "weighted avg       0.78      0.78      0.78       379\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:21.416 | INFO     | __main__:<module>:18 - Training classifier: GradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:21.416366+0100\u001b[0m \u001b[1mTraining classifier: GradientBoostingClassifier\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.349 | INFO     | __main__:<module>:24 - Results for GradientBoostingClassifier:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.349725+0100\u001b[0m \u001b[1mResults for GradientBoostingClassifier:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.354 | INFO     | __main__:<module>:25 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.38      0.35        40\n",
      "           2       0.80      0.84      0.82       211\n",
      "           3       0.25      0.20      0.22         5\n",
      "           4       0.80      0.72      0.76        71\n",
      "           5       1.00      0.85      0.92        52\n",
      "\n",
      "    accuracy                           0.76       379\n",
      "   macro avg       0.64      0.60      0.61       379\n",
      "weighted avg       0.77      0.76      0.77       379\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.354307+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.38      0.35        40\n",
      "           2       0.80      0.84      0.82       211\n",
      "           3       0.25      0.20      0.22         5\n",
      "           4       0.80      0.72      0.76        71\n",
      "           5       1.00      0.85      0.92        52\n",
      "\n",
      "    accuracy                           0.76       379\n",
      "   macro avg       0.64      0.60      0.61       379\n",
      "weighted avg       0.77      0.76      0.77       379\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.358 | INFO     | __main__:<module>:18 - Training classifier: DecisionTreeClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.358296+0100\u001b[0m \u001b[1mTraining classifier: DecisionTreeClassifier\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.422 | INFO     | __main__:<module>:24 - Results for DecisionTreeClassifier:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.422718+0100\u001b[0m \u001b[1mResults for DecisionTreeClassifier:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.426 | INFO     | __main__:<module>:25 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.38      0.29        40\n",
      "           2       0.78      0.69      0.74       211\n",
      "           3       0.12      0.20      0.15         5\n",
      "           4       0.54      0.55      0.55        71\n",
      "           5       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.64       379\n",
      "   macro avg       0.50      0.52      0.50       379\n",
      "weighted avg       0.68      0.64      0.65       379\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.426490+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.38      0.29        40\n",
      "           2       0.78      0.69      0.74       211\n",
      "           3       0.12      0.20      0.15         5\n",
      "           4       0.54      0.55      0.55        71\n",
      "           5       0.82      0.77      0.79        52\n",
      "\n",
      "    accuracy                           0.64       379\n",
      "   macro avg       0.50      0.52      0.50       379\n",
      "weighted avg       0.68      0.64      0.65       379\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.428 | INFO     | __main__:<module>:18 - Training classifier: KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.428613+0100\u001b[0m \u001b[1mTraining classifier: KNeighborsClassifier\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.595 | INFO     | __main__:<module>:24 - Results for KNeighborsClassifier:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.595849+0100\u001b[0m \u001b[1mResults for KNeighborsClassifier:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.598 | INFO     | __main__:<module>:25 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.57      0.38        40\n",
      "           2       0.71      0.81      0.76       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.90      0.39      0.55        71\n",
      "           5       0.97      0.54      0.69        52\n",
      "\n",
      "    accuracy                           0.66       379\n",
      "   macro avg       0.57      0.46      0.48       379\n",
      "weighted avg       0.73      0.66      0.66       379\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.598319+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.28      0.57      0.38        40\n",
      "           2       0.71      0.81      0.76       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.90      0.39      0.55        71\n",
      "           5       0.97      0.54      0.69        52\n",
      "\n",
      "    accuracy                           0.66       379\n",
      "   macro avg       0.57      0.46      0.48       379\n",
      "weighted avg       0.73      0.66      0.66       379\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.601 | INFO     | __main__:<module>:18 - Training classifier: SGDClassifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.601329+0100\u001b[0m \u001b[1mTraining classifier: SGDClassifier\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.728 | INFO     | __main__:<module>:24 - Results for SGDClassifier:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.728992+0100\u001b[0m \u001b[1mResults for SGDClassifier:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.730 | INFO     | __main__:<module>:25 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.50      0.43        40\n",
      "           2       0.83      0.82      0.82       211\n",
      "           3       0.50      0.40      0.44         5\n",
      "           4       0.78      0.73      0.75        71\n",
      "           5       0.98      0.90      0.94        52\n",
      "\n",
      "    accuracy                           0.77       379\n",
      "   macro avg       0.69      0.67      0.68       379\n",
      "weighted avg       0.79      0.77      0.78       379\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.730921+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.37      0.50      0.43        40\n",
      "           2       0.83      0.82      0.82       211\n",
      "           3       0.50      0.40      0.44         5\n",
      "           4       0.78      0.73      0.75        71\n",
      "           5       0.98      0.90      0.94        52\n",
      "\n",
      "    accuracy                           0.77       379\n",
      "   macro avg       0.69      0.67      0.68       379\n",
      "weighted avg       0.79      0.77      0.78       379\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# models to test\n",
    "classifiers = [\n",
    "    LogisticRegression(solver=\"saga\", random_state=42, n_jobs=-1, penalty='l1'),\n",
    "    RandomForestClassifier(random_state=42, n_estimators=500, n_jobs=-1, criterion='gini', max_features='sqrt'),\n",
    "    GradientBoostingClassifier(n_estimators=500, random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42, criterion='entropy', max_features='sqrt'), \n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=7),\n",
    "    SGDClassifier(n_jobs=-1)\n",
    "]\n",
    "\n",
    "# get names of the objects in list \n",
    "names = [re.match(r\"[^\\(]+\", name.__str__())[0] for name in classifiers]\n",
    "logger.info(f\"Classifiers to test: {names}\")\n",
    "\n",
    "# test all classifiers and save pred. results on test data\n",
    "results = {}\n",
    "for name, clf in zip(names, classifiers):\n",
    "    logger.info(f\"Training classifier: {name}\")\n",
    "    clf.fit(train_x_vec, train_y)\n",
    "    prediction = clf.predict(test_x_vec)\n",
    "    report = classification_report(test_y, prediction)\n",
    "    results[name] = report\n",
    "\n",
    "    logger.info(f\"Results for {name}:\")\n",
    "    logger.info(f\"{report}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e009ad1",
   "metadata": {},
   "source": [
    "### Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9543743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"svc\", LinearSVC())])\n",
    "\n",
    "# params = {\n",
    "#     \"tfidf__ngram_range\": [(1, 2)],\n",
    "#     \"tfidf__max_df\": [0.1, 0.3, 0.5, 0.7],\n",
    "#     \"tfidf__min_df\": [10, 30, 50, 70],\n",
    "#     \"svc__C\": np.arange(0.2, 1, 0.2),\n",
    "#     \"svc__penalty\": ['l2'],\n",
    "#     \"svc__max_iter\": [5000],\n",
    "# }\n",
    "\n",
    "# pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\", verbose=2)\n",
    "# pipe_clf.fit(processed_data, target)\n",
    "# best_params = pipe_clf.best_params_\n",
    "# print(best_params)\n",
    "\n",
    "# # run pipe with optimized parameters\n",
    "# pipe.set_params(**best_params).fit(train_x, train_y)\n",
    "# pipe_pred = pipe.predict(test_x)\n",
    "# report = classification_report(test_y, pipe_pred)\n",
    "# print(report)\n",
    "\n",
    "# with open('configs/svc.json', 'w') as file:\n",
    "#      file.write(json.dumps(best_params))\n",
    "        \n",
    "# pipe.set_params(**best_params).fit(processed_data, target)\n",
    "# dump(pipe, filename=\"trained_models/model_svc.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8335e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:26:41.767 | INFO     | __main__:<module>:6 - {'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'logreg__solver': ['newton-cg', 'liblinear', 'sag'], 'logreg__penalty': ['l1', 'l2', 'elasticnet'], 'logreg__max_iter': [2000]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:26:41.767288+0100\u001b[0m \u001b[1m{'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'logreg__solver': ['newton-cg', 'liblinear', 'sag'], 'logreg__penalty': ['l1', 'l2', 'elasticnet'], 'logreg__max_iter': [2000]}\u001b[0m\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:27:16.199 | INFO     | __main__:<module>:11 - {'logreg__max_iter': 2000, 'logreg__penalty': 'l2', 'logreg__solver': 'newton-cg', 'tfidf__max_df': 0.7, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:27:16.199748+0100\u001b[0m \u001b[1m{'logreg__max_iter': 2000, 'logreg__penalty': 'l2', 'logreg__solver': 'newton-cg', 'tfidf__max_df': 0.7, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:27:16.380 | INFO     | __main__:<module>:17 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.40      0.40        40\n",
      "           2       0.81      0.88      0.84       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.81      0.72      0.76        71\n",
      "           5       1.00      0.87      0.93        52\n",
      "\n",
      "    accuracy                           0.79       379\n",
      "   macro avg       0.60      0.57      0.59       379\n",
      "weighted avg       0.78      0.79      0.78       379\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:27:16.380654+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.40      0.40        40\n",
      "           2       0.81      0.88      0.84       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.81      0.72      0.76        71\n",
      "           5       1.00      0.87      0.93        52\n",
      "\n",
      "    accuracy                           0.79       379\n",
      "   macro avg       0.60      0.57      0.59       379\n",
      "weighted avg       0.78      0.79      0.78       379\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_models/model_logreg.sav']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"logreg\", LogisticRegression(n_jobs=-1))])\n",
    "\n",
    "with open(\"gridsearch_space/model_logreg.json\", \"r\") as gs_file:\n",
    "    contents = gs_file.read()\n",
    "    params = ast.literal_eval(contents)\n",
    "    logger.info(params)\n",
    "    \n",
    "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\", verbose=2)\n",
    "pipe_clf.fit(processed_data, target)\n",
    "best_params = pipe_clf.best_params_\n",
    "logger.info(best_params)\n",
    "\n",
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params).fit(train_x, train_y)\n",
    "pipe_pred = pipe.predict(test_x)\n",
    "report = classification_report(test_y, pipe_pred)\n",
    "logger.info(report)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(test_y, pipe_pred, average='macro')\n",
    "metrics_list.append(['model_logreg', precision, recall, fscore])\n",
    "\n",
    "with open('configs/logreg.json', 'w') as file:\n",
    "     file.write(json.dumps(best_params))\n",
    "        \n",
    "pipe.set_params(**best_params).fit(processed_data, target)\n",
    "dump(pipe, filename=\"trained_models/model_logreg.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21af897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:29:10.706 | INFO     | __main__:<module>:6 - {'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'dtree__criterion': ['gini', 'entropy'], 'dtree__max_features': ['sqrt', 'log2']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:29:10.706654+0100\u001b[0m \u001b[1m{'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'dtree__criterion': ['gini', 'entropy'], 'dtree__max_features': ['sqrt', 'log2']}\u001b[0m\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:29:23.855 | INFO     | __main__:<module>:11 - {'dtree__criterion': 'gini', 'dtree__max_features': 'sqrt', 'tfidf__max_df': 0.7, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:29:23.855349+0100\u001b[0m \u001b[1m{'dtree__criterion': 'gini', 'dtree__max_features': 'sqrt', 'tfidf__max_df': 0.7, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:29:23.956 | INFO     | __main__:<module>:17 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.55      0.42        40\n",
      "           2       0.83      0.73      0.77       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.70      0.69      0.70        71\n",
      "           5       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.70       379\n",
      "   macro avg       0.53      0.56      0.54       379\n",
      "weighted avg       0.74      0.70      0.72       379\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:29:23.956173+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.55      0.42        40\n",
      "           2       0.83      0.73      0.77       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.70      0.69      0.70        71\n",
      "           5       0.80      0.83      0.81        52\n",
      "\n",
      "    accuracy                           0.70       379\n",
      "   macro avg       0.53      0.56      0.54       379\n",
      "weighted avg       0.74      0.70      0.72       379\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_models/model_dectree.sav']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"dtree\", DecisionTreeClassifier())])\n",
    "\n",
    "with open(\"gridsearch_space/model_dectree.json\", \"r\") as gs_file:\n",
    "    contents = gs_file.read()\n",
    "    params = ast.literal_eval(contents)\n",
    "    logger.info(params)\n",
    "\n",
    "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\", verbose=2)\n",
    "pipe_clf.fit(processed_data, target)\n",
    "best_params = pipe_clf.best_params_\n",
    "logger.info(best_params)\n",
    "\n",
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params).fit(train_x, train_y)\n",
    "pipe_pred = pipe.predict(test_x)\n",
    "report = classification_report(test_y, pipe_pred)\n",
    "logger.info(report)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(test_y, pipe_pred, average='macro')\n",
    "metrics_list.append(['model_dectree', precision, recall, fscore])\n",
    "\n",
    "with open('configs/dectree.json', 'w') as file:\n",
    "     file.write(json.dumps(best_params))\n",
    "\n",
    "pipe.set_params(**best_params).fit(processed_data, target)\n",
    "dump(pipe, filename=\"trained_models/model_dectree.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ccd5bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:30:10.166 | INFO     | __main__:<module>:6 - {'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'knc__algorithm': ['ball_tree', 'kd_tree'], 'knc__n_neighbors': [3, 5, 7]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:30:10.166759+0100\u001b[0m \u001b[1m{'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'knc__algorithm': ['ball_tree', 'kd_tree'], 'knc__n_neighbors': [3, 5, 7]}\u001b[0m\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:30:37.697 | INFO     | __main__:<module>:11 - {'knc__algorithm': 'ball_tree', 'knc__n_neighbors': 7, 'tfidf__max_df': 0.5, 'tfidf__min_df': 50, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:30:37.697264+0100\u001b[0m \u001b[1m{'knc__algorithm': 'ball_tree', 'knc__n_neighbors': 7, 'tfidf__max_df': 0.5, 'tfidf__min_df': 50, 'tfidf__ngram_range': (1, 2)}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:30:37.940 | INFO     | __main__:<module>:17 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.50      0.33        40\n",
      "           2       0.75      0.76      0.76       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.70      0.45      0.55        71\n",
      "           5       0.92      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.65       379\n",
      "   macro avg       0.52      0.47      0.48       379\n",
      "weighted avg       0.70      0.65      0.66       379\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:30:37.940412+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.25      0.50      0.33        40\n",
      "           2       0.75      0.76      0.76       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.70      0.45      0.55        71\n",
      "           5       0.92      0.65      0.76        52\n",
      "\n",
      "    accuracy                           0.65       379\n",
      "   macro avg       0.52      0.47      0.48       379\n",
      "weighted avg       0.70      0.65      0.66       379\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_models/model_kneg.sav']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"knc\", KNeighborsClassifier(n_jobs=-1))])\n",
    "\n",
    "with open(\"gridsearch_space/model_kneg.json\", \"r\") as gs_file:\n",
    "    contents = gs_file.read()\n",
    "    params = ast.literal_eval(contents)\n",
    "    logger.info(params)\n",
    "\n",
    "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\", verbose=2)\n",
    "pipe_clf.fit(processed_data, target)\n",
    "best_params = pipe_clf.best_params_\n",
    "logger.info(best_params)\n",
    "\n",
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params).fit(train_x, train_y)\n",
    "pipe_pred = pipe.predict(test_x)\n",
    "report = classification_report(test_y, pipe_pred)\n",
    "logger.info(report)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(test_y, pipe_pred, average='macro')\n",
    "metrics_list.append(['model_kneg', precision, recall, fscore])\n",
    "\n",
    "with open('configs/kneg.json', 'w') as file:\n",
    "     file.write(json.dumps(best_params))\n",
    "        \n",
    "pipe.set_params(**best_params).fit(processed_data, target)\n",
    "dump(pipe, filename=\"trained_models/model_kneg.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee92f7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:31:29.480 | INFO     | __main__:<module>:6 - {'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'rfc__criterion': ['gini', 'entropy'], 'rfc__n_estimators': [1000], 'rfc__max_features': ['sqrt', 'log2']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:31:29.480293+0100\u001b[0m \u001b[1m{'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'rfc__criterion': ['gini', 'entropy'], 'rfc__n_estimators': [1000], 'rfc__max_features': ['sqrt', 'log2']}\u001b[0m\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:44:43.190 | INFO     | __main__:<module>:11 - {'rfc__criterion': 'entropy', 'rfc__max_features': 'sqrt', 'rfc__n_estimators': 1000, 'tfidf__max_df': 0.5, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:44:43.190466+0100\u001b[0m \u001b[1m{'rfc__criterion': 'entropy', 'rfc__max_features': 'sqrt', 'rfc__n_estimators': 1000, 'tfidf__max_df': 0.5, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:44:47.489 | INFO     | __main__:<module>:17 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.53      0.45        40\n",
      "           2       0.84      0.85      0.85       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.83      0.76      0.79        71\n",
      "           5       1.00      0.88      0.94        52\n",
      "\n",
      "    accuracy                           0.79       379\n",
      "   macro avg       0.61      0.60      0.61       379\n",
      "weighted avg       0.80      0.79      0.80       379\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:44:47.489483+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.53      0.45        40\n",
      "           2       0.84      0.85      0.85       211\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.83      0.76      0.79        71\n",
      "           5       1.00      0.88      0.94        52\n",
      "\n",
      "    accuracy                           0.79       379\n",
      "   macro avg       0.61      0.60      0.61       379\n",
      "weighted avg       0.80      0.79      0.80       379\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_models/model_ranfor.sav']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"rfc\", RandomForestClassifier(n_jobs=-1))])\n",
    "\n",
    "with open(\"gridsearch_space/model_ranfor.json\", \"r\") as gs_file:\n",
    "    contents = gs_file.read()\n",
    "    params = ast.literal_eval(contents)\n",
    "    logger.info(params)\n",
    "\n",
    "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\", verbose=2)\n",
    "pipe_clf.fit(processed_data, target)\n",
    "best_params = pipe_clf.best_params_\n",
    "logger.info(best_params)\n",
    "\n",
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params).fit(train_x, train_y)\n",
    "pipe_pred = pipe.predict(test_x)\n",
    "report = classification_report(test_y, pipe_pred)\n",
    "logger.info(report)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(test_y, pipe_pred, average='macro')\n",
    "metrics_list.append(['model_ranfor', precision, recall, fscore])\n",
    "\n",
    "with open('configs/ranfor.json', 'w') as file:\n",
    "     file.write(json.dumps(best_params))\n",
    "        \n",
    "pipe.set_params(**best_params).fit(processed_data, target)\n",
    "dump(pipe, filename=\"trained_models/model_ranfor.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "442bc493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:51:29.310 | INFO     | __main__:<module>:6 - {'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'gbc__learning_rate': [0.001, 0.01], 'gbc__max_features': ['sqrt', 'log2'], 'gbc__n_estimators': [1000]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:51:29.310169+0100\u001b[0m \u001b[1m{'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'gbc__learning_rate': [0.001, 0.01], 'gbc__max_features': ['sqrt', 'log2'], 'gbc__n_estimators': [1000]}\u001b[0m\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 18:13:56.275 | INFO     | __main__:<module>:11 - {'gbc__learning_rate': 0.01, 'gbc__max_features': 'sqrt', 'gbc__n_estimators': 1000, 'tfidf__max_df': 0.3, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T18:13:56.275885+0100\u001b[0m \u001b[1m{'gbc__learning_rate': 0.01, 'gbc__max_features': 'sqrt', 'gbc__n_estimators': 1000, 'tfidf__max_df': 0.3, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 18:14:03.897 | INFO     | __main__:<module>:17 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.38      0.39        40\n",
      "           2       0.80      0.89      0.84       211\n",
      "           3       0.33      0.20      0.25         5\n",
      "           4       0.86      0.72      0.78        71\n",
      "           5       0.96      0.85      0.90        52\n",
      "\n",
      "    accuracy                           0.79       379\n",
      "   macro avg       0.67      0.61      0.63       379\n",
      "weighted avg       0.79      0.79      0.78       379\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T18:14:03.897929+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.42      0.38      0.39        40\n",
      "           2       0.80      0.89      0.84       211\n",
      "           3       0.33      0.20      0.25         5\n",
      "           4       0.86      0.72      0.78        71\n",
      "           5       0.96      0.85      0.90        52\n",
      "\n",
      "    accuracy                           0.79       379\n",
      "   macro avg       0.67      0.61      0.63       379\n",
      "weighted avg       0.79      0.79      0.78       379\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_models/model_gradboost.sav']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"gbc\", GradientBoostingClassifier())])\n",
    "\n",
    "with open(\"gridsearch_space/model_gradboost.json\", \"r\") as gs_file:\n",
    "    contents = gs_file.read()\n",
    "    params = ast.literal_eval(contents)\n",
    "    logger.info(params)\n",
    "\n",
    "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\", verbose=2)\n",
    "pipe_clf.fit(processed_data, target)\n",
    "best_params = pipe_clf.best_params_\n",
    "logger.info(best_params)\n",
    "\n",
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params).fit(train_x, train_y)\n",
    "pipe_pred = pipe.predict(test_x)\n",
    "report = classification_report(test_y, pipe_pred)\n",
    "logger.info(report)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(test_y, pipe_pred, average='macro')\n",
    "metrics_list.append(['model_gradboost', precision, recall, fscore])\n",
    "\n",
    "with open('configs/gradboost.json', 'w') as file:\n",
    "     file.write(json.dumps(best_params))\n",
    "\n",
    "pipe.set_params(**best_params).fit(processed_data, target)\n",
    "dump(pipe_clf, filename=\"trained_models/model_gradboost.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a929481",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:46:30.933 | INFO     | __main__:<module>:6 - {'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'sgd__alpha': [0.0001, 0.001], 'sgd__max_iter': [2000], 'sgd__tol': [0.0001, 0.001], 'sgd__loss': ['modified_huber']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:46:30.933251+0100\u001b[0m \u001b[1m{'tfidf__ngram_range': [(1, 2)], 'tfidf__max_df': [0.1, 0.3, 0.5, 0.7], 'tfidf__min_df': [10, 30, 50, 70], 'sgd__alpha': [0.0001, 0.001], 'sgd__max_iter': [2000], 'sgd__tol': [0.0001, 0.001], 'sgd__loss': ['modified_huber']}\u001b[0m\n",
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:46:48.341 | INFO     | __main__:<module>:11 - {'sgd__alpha': 0.0001, 'sgd__loss': 'modified_huber', 'sgd__max_iter': 2000, 'sgd__tol': 0.0001, 'tfidf__max_df': 0.3, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:46:48.341700+0100\u001b[0m \u001b[1m{'sgd__alpha': 0.0001, 'sgd__loss': 'modified_huber', 'sgd__max_iter': 2000, 'sgd__tol': 0.0001, 'tfidf__max_df': 0.3, 'tfidf__min_df': 10, 'tfidf__ngram_range': (1, 2)}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:46:48.554 | INFO     | __main__:<module>:17 -               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.60      0.48        40\n",
      "           2       0.84      0.77      0.80       211\n",
      "           3       0.17      0.20      0.18         5\n",
      "           4       0.75      0.76      0.76        71\n",
      "           5       0.96      0.87      0.91        52\n",
      "\n",
      "    accuracy                           0.76       379\n",
      "   macro avg       0.62      0.64      0.63       379\n",
      "weighted avg       0.78      0.76      0.77       379\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:46:48.554019+0100\u001b[0m \u001b[1m              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.60      0.48        40\n",
      "           2       0.84      0.77      0.80       211\n",
      "           3       0.17      0.20      0.18         5\n",
      "           4       0.75      0.76      0.76        71\n",
      "           5       0.96      0.87      0.91        52\n",
      "\n",
      "    accuracy                           0.76       379\n",
      "   macro avg       0.62      0.64      0.63       379\n",
      "weighted avg       0.78      0.76      0.77       379\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['trained_models/model_sgd.sav']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"sgd\", SGDClassifier(n_jobs=-1))])\n",
    "\n",
    "with open(\"gridsearch_space/model_sgd.json\", \"r\") as gs_file:\n",
    "    contents = gs_file.read()\n",
    "    params = ast.literal_eval(contents)\n",
    "    logger.info(params)\n",
    "    \n",
    "pipe_clf = GridSearchCV(pipe, params, n_jobs=-1, scoring=\"f1_macro\", verbose=2)\n",
    "pipe_clf.fit(processed_data, target)\n",
    "best_params = pipe_clf.best_params_\n",
    "logger.info(best_params)\n",
    "\n",
    "# run pipe with optimized parameters\n",
    "pipe.set_params(**best_params).fit(train_x, train_y)\n",
    "pipe_pred = pipe.predict(test_x)\n",
    "report = classification_report(test_y, pipe_pred)\n",
    "logger.info(report)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(test_y, pipe_pred, average='macro')\n",
    "metrics_list.append(['model_sgd', precision, recall, fscore])\n",
    "\n",
    "with open('configs/sgd.json', 'w') as file:\n",
    "     file.write(json.dumps(best_params))\n",
    "\n",
    "pipe.set_params(**best_params).fit(processed_data, target)\n",
    "dump(pipe, filename=\"trained_models/model_sgd.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36b41c",
   "metadata": {},
   "source": [
    "### Best trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf48669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-23 17:47:11.403 | INFO     | __main__:<module>:9 - Copied trained_models/model_logreg.sav as best_model.sav\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-12-23T17:47:11.403434+0100\u001b[0m \u001b[1mCopied trained_models/model_logreg.sav as best_model.sav\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics_list, columns=['model', 'precision', 'recall', 'fscore'])\n",
    "\n",
    "compare_model_metric = 'fscore'\n",
    "metrics_df = metrics_df.sort_values(compare_model_metric, ascending=False)\n",
    "\n",
    "best_trained_model_filename = 'trained_models/' + metrics_df.loc[0]['model'] + '.sav'\n",
    "\n",
    "copy(best_trained_model_filename, 'trained_models/best_model.sav')\n",
    "logger.info(f'Copied {best_trained_model_filename} as best_model.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05869331",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6295cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unklar': 0.2409734196506198,\n",
       " 'unklar-an-vn': 0.5556520310353268,\n",
       " 'an-ta': 0.03953945454337567,\n",
       " 'an-vn-bekanntes-konto': 0.0936289121749357,\n",
       " 'benanntes-konto-im-text': 0.0702061825957421}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"kundin frau vertragsnummer tierarztrechnungzugesandtrechnung anhang beigefugt\"\n",
    "mapping_dict = load_mapping(mapping_file='dataset/mapping.yaml')\n",
    "pipeline = load('trained_models/best_model.sav')\n",
    "\n",
    "stopwords_locale = 'german'\n",
    "stemmer = SnowballStemmer(stopwords_locale)\n",
    "\n",
    "with open('dataset/stopwords.yaml', 'r') as f:\n",
    "    curated_stop_words = yaml.safe_load(f)\n",
    "\n",
    "stop_words = set(stopwords.words(stopwords_locale))\n",
    "\n",
    "text = preprocess_single_text(text, \n",
    "                              stop_words=stop_words, \n",
    "                              curated_stop_words=curated_stop_words,\n",
    "                              stemming=True, \n",
    "                              stemmer=stemmer)\n",
    "\n",
    "result = {}\n",
    "for cls, prob in zip(pipeline.classes_.tolist(), pipeline.predict_proba([text]).tolist().pop()):\n",
    "    result[mapping_dict[cls]] = prob\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea7f1fbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "text_1\n",
      "1 0.0\n",
      "2 1.0\n",
      "3 0.0\n",
      "4 0.0\n",
      "5 0.0\n",
      "model_sgd \t :: \t unklar-an-vn \t :: \t unklar \n",
      " {'unklar': 0.0, 'unklar-an-vn': 1.0, 'an-ta': 0.0, 'an-vn-bekanntes-konto': 0.0, 'benanntes-konto-im-text': 0.0} \n",
      "\n",
      "0 0.21472550453649922\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-ac89de2cc848>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmapping_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Subject  Vertragsnummer: 1 750 649 32 From:  giuseppe.infantolino@barmenia.de  To:  schaden@barmenia.de Sent Tue, 12 Oct 2021 11:55;59 +0200 CamScanner 10-12-2021 11.40.pdf Guten Tag, die Kundin Frau Melike Toplugedik mit der Vertragsnummer 1 750 649 32, hat mir die Tierarztrechnung  zugesandt. Rechnung ist im Anhang beigefügt. Mit freundlichen Grüßen Giuseppe Infantolino Viele Grüße aus dem schönen Saarland Barmenia Versicherungen Bous Saar Giuseppe Infantolino  Versicherungsfachmann IHK  66359 Bous Saar Mobil: (0160) 1540589 Mail : giuseppe . inf antolino@barmenia . de Homepage : https : / / agentur . barmenia .de/qiuseppe_infantolino Bezirksdirektion: www . barmenia—saarbruecken . de Termine nur nach Vereinbarung #MachenWirGern Meine Beratungsgrundlage Ich bin für die Barmenia Krankenversicherung a.G. als gebundene Versicherungsvertreter tätig und berate Sie ausschließlich über die Produkte der Barmenia Krankenversicherung AG Barmenia Lebensversicherung a.G Barmenia Allgemeine Versicherungs-AG Roland Rechtschutz-Versicherung-AG Roland Schutzbrief-Versicherung a.G Schlichtungssteilen H’ij r Lebens— und Sachversicherungen: Verein Versicherungsombudsmann e.V.  Postfach 080632  10006 Berlin Für private Krankenve n : Ombudsmann für private Kranken- und Pflegeversicherung Postfach 060222 10052 Berlin\",\n",
    "    \"From:  Bartolomeo Cellammare <bartolomeo.cellammare@web.de>  To:  tierarztrechnung@barmenia.de Subject  Leistungsfall Katze Elis, Vers. Nr.: 302083555 Thu, 21 Oct 2021 14:10:18+0200 Sent 1 .jpeg  2.jpeg  3.jpeg  4,jpeg 54 ♦In! 6.jpeg Sehr geehrte Damen und Herren, leider ist unsere Katze erkrankt und reiche ihnen für die Leistungsbearbeitung die Rechnungen vom Tierarzt ein,  mit der Bitte um Begleichung. Vielen Dank im Voraus für die Mühe. Beste Grüße B. Cellammare\",\n",
    "    \"From:  Info-KB <info-kb@barmenia.de> To:  Schaden <schaden@barmenia.de> Subject:  WG: Abtrittserklärung auf dauer!!! Sent: Tue, 12 Oct 2021 08:32:58 +0000 Von: Info <info@barmenia.de> Gesendet: Dienstag, 12. Oktober 2021 09:58 An: Info-KB <info-kb@barmenia.de> Betreff: FW: Abtrittserklärung auf dauer!!! From: Heiko Giese <heiko.giese.voss@gmail.com<mailto:heiko.giese.voss@gmail.com» Sent: Dienstag, 12. Oktober 2021 07:39:19 To: Info Subject: Abtrittserklärung auf dauer! ! ! Sehr geehrte Damen u. Herren Hiermit möchte ich meine Abtrittserklärung für meine Versicherung Nr.178718252 auf dauer mitteilen.Rechnungen die von meinem Tierarzt Dr.H.D.Bertelsmann , kleintierpraxis Möhnestr.106, 59755 Arnsberg kommen sollen alle in Zukunft mit dem Arzt abgerechnet werden.Hier die  Kontodaten vom Tierarzt. Deutsche Bank PBK Iban: DE 64466700240500700000 Bic: DEUTDEDB961 MfgSusanne Giese-Wiemann Mobil: 016092136774\",\n",
    "    \"  Bettina Redöhl, Kugelfangtrift 196, 30657 Hannover  Tel.: 0176/61 666 192 Bettina RedOhl, Kuoefengtrift 196, 30657 Ht IIllIsh‘A-1i Einschreiben/Einwurf Barmenia Allgemeine Versicherungs-AG Hauptverwaltung gAR wesa-) Barmenis-Allee1 202) 42119 Wuppertal 2% VW vt t, ginsC Hannover, 19.10.2021 Vertragsnummer 179479473  Rechnungen Tierklinik Sehr geehrte Damen und Herren, als Anlage übersende ich Ihnen die Rechnungen der Tierärzte am Lohner Weg, mit Bitte um Erstattung  der Rechnungsbeträge auf das Ihnen bekannte Konto. Bei weiteren Fragen stehen die o.g. Tierärzte bzw. die Tierärztin Frau Dr. Bensch, Sutelstr. 14, 30659  Hannover, Tel.: 0511/6463639 zur Verfügung. Vielen Dank. Bei weiteren Fragen stehe ich Ihnen gern zur Verfügung. Mit freundlichen GrüBen  g /2g/ Bettina Redöhl Anlagen\",\n",
    "    \"From:  Marijke Holtkamp <m.etzrodtgweb.de> To:  tierarztrechnung@barmenia.de Subject  Tierarztrechungen Sent Thu, 21 Oct 2021 14:28:46+0200 IMG 2798.JPG IMG_2799.JPG Sehr geehrte Damen und Herren,  anbei sende ich Ihnen die Tierarztrechnung unserer Hündin Clara Tari mit der bitte um Erstattung: KreisSparkasse Köln DE 74 3705 0299 1152 0271 47 BIC COKSDE33xxX Vielen Dank.! Mit freundlichem Gruß  Marijke Holtkamp\"\n",
    "]\n",
    "text_labels = ['unklar', 'unklar-an-vn', 'an-ta', 'an-vn-bekanntes-konto', 'benanntes-konto-im-text']\n",
    "mapping_dict = load_mapping(mapping_file='dataset/mapping.yaml')\n",
    "\n",
    "for ind, text in enumerate(texts):\n",
    "    print(f'\\ntext_{ind+1}')\n",
    "    for model in ['model_sgd', 'model_gradboost', 'model_ranfor', 'model_kneg', 'model_dectree', 'model_logreg']:\n",
    "        pipeline = load(f'trained_models/{model}.sav')\n",
    "\n",
    "        stopwords_locale = 'german'\n",
    "        stemmer = SnowballStemmer(stopwords_locale)\n",
    "\n",
    "        with open('dataset/stopwords.yaml', 'r') as f:\n",
    "            curated_stop_words = yaml.safe_load(f)\n",
    "\n",
    "        stop_words = set(stopwords.words(stopwords_locale))\n",
    "\n",
    "        text = preprocess_single_text(text, \n",
    "                                      stop_words=stop_words, \n",
    "                                      curated_stop_words=curated_stop_words,\n",
    "                                      stemming=True, \n",
    "                                      stemmer=stemmer)\n",
    "\n",
    "        result = {}\n",
    "        for cls, prob in zip(pipeline.classes_.tolist(), pipeline.predict_proba([text]).tolist().pop()):\n",
    "            print(cls, prob)\n",
    "            result[mapping_dict[cls]] = prob\n",
    "            predicted_class = pipeline.predict([text]).tolist().pop()\n",
    "\n",
    "        print(model,'\\t :: \\t', mapping_dict[predicted_class], '\\t :: \\t', text_labels[ind], '\\n', result, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "840eb70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'unklar',\n",
       " '2': 'unklar-an-vn',\n",
       " '3': 'an-ta',\n",
       " '4': 'an-vn-bekanntes-konto',\n",
       " '5': 'benanntes-konto-im-text'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840fc6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiermit mochte abtrittserklarung versicherung nr daur mitteilenrechnungen tierarzt drhdbertelsmann \n",
    "kleintierpraxis mohnestr arnsberg kommen sollen zukunft arzt abgerechnet werdenhier kontodaten tierarzt\n",
    "\n",
    "Hiermit möchte ich meine Abtrittserklärung für meine Versicherung Nr.178718252 auf dauer mitteilen.Rechnungen die von meinem Tierarzt Dr.H.D.Bertelsmann , kleintierpraxis Möhnestr.106, 59755Arnsberg kommen sollen alle in Zukunft mit dem Arzt abgerechnet werden.Hier die  Kontodaten vom Tierarzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9107cf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.7, min_df=10, ngram_range=(1, 2))),\n",
       "                ('logreg',\n",
       "                 LogisticRegression(max_iter=2000, n_jobs=-1,\n",
       "                                    solver='newton-cg'))])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = load(f'trained_models/best_model.sav')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60a4b0",
   "metadata": {},
   "source": [
    "### Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f713fe23",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc1f2499860>: Failed to establish a new connection: [Errno 61] Connection refused',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             )\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             )\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1287\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1332\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1333\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             )\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x7fc1f2499860>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    755\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             )\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc1f2499860>: Failed to establish a new connection: [Errno 61] Connection refused',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-53bd5ac748c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m r = requests.post(url,\n\u001b[1;32m      5\u001b[0m                   json={\n\u001b[0;32m----> 6\u001b[0;31m                       \u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"kundin frau vertragsnummer tierarztrechnungzugesandtrechnung anhang beigefugt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                   }\n\u001b[1;32m      8\u001b[0m                  )\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \"\"\"\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/miniconda3/envs/venv/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fc1f2499860>: Failed to establish a new connection: [Errno 61] Connection refused',))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://localhost:5000/'\n",
    "r = requests.post(url,\n",
    "                  json={\n",
    "                      'text':\"kundin frau vertragsnummer tierarztrechnungzugesandtrechnung anhang beigefugt\"\n",
    "                  }\n",
    "                 )\n",
    "\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec677ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
